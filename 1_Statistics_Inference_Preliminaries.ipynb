{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmtJ5gvBW4WLHOHT+E+GS8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrSubbiah/Frequentist_Stats/blob/main/1_Statistics_Inference_Preliminaries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=maroon>Introduction\n",
        "\n",
        "This notes provides few ideas of sampling distribution of sample mean and variance\n",
        "\n",
        "**<font color=blue>Suggested Reading: [CABE] Casella, G., & Berger, R. L. (2002). Statistical inference (Vol. 2). Pacific Grove, CA: Duxbury; specifically, Chapters 3 and 5</span>**\n",
        "\n",
        "**<font color=violet>Keywords:**\n",
        "\n",
        "* Long-run probability\n",
        "* Theoretical Distributions\n",
        "* Target Population\n",
        "* Sampled Population\n",
        "* Random Sample\n",
        "* Statistics\n",
        "\n",
        "## Sampling Distribution \n",
        "\n",
        "Frequntist probability of an event $\\mathcal{A}$ (from a random experiment, $\\mathcal{E}$) is based on relative frequency (number of times $\\mathcal{A}$ is repeated) in many trials of $\\mathcal{E}$. Here, probability is defined as a repeatable objective way out of \"sufficiently\" long-run of the experiment. This may be understood as\n",
        "\n",
        "$$p(\\mathcal{A})= \\lim_{n \\to \\infty} \\frac{m}{n}$$\n",
        "\n",
        "where $n$ is the number of trials of $\\mathcal{E}$ and $m$ is  the frequency of $\\mathcal{A}$ in $n$ trials\n",
        "\n",
        "This basic notion is considered while building the inferential principles of frequntist statistics. Most of the studies (involved with random experiments) are conducted with samples drawn from a study population which is a part (or subset) of a target population about which the study is aimed to generalize the findings from sample. In this process, data is expected to be a repeatable process in that samples are drawn from many trials. There could be many sampling methods through which data are collected for a reasonable way to get representative samples so as to generealize the quantity of interest (parameter) about the population. Further, it is assemed that parameters are fixed constant but random and **inference** about it can be done via the samples\n",
        "\n",
        "While doing so, it is assuemd that (theoretically) once the quantity leading to the parameter is calculated from each sample for \"sufficiently large\" number of times. That gives a distribution of values for the parameter calculated from the sample which is called **statistic** and the distribution is said to be **Sampling distribution** "
      ],
      "metadata": {
        "id": "nnshtp_tjlTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=maroon> An Example - Sampling Distribution\n",
        "\n",
        "Let us consider our population is Uniform (0,1). So population mean is 0.5\n",
        "\n",
        "Now we shall sample (of fixwd size 'n') from this hypothetical population \n",
        "\n",
        "Calculate mean of these sampled items\n",
        "\n",
        "Repeat the process for \"sufficently\" large number (k) of times\n",
        "\n",
        "## <font color=darkblue> Following code is generating 5 (k) samples each of size 100 (n) to \"sample\" 5 items from the population and calculate the mean (Quantity of interest about population). This will yield 100 values that forms a distribution, called Sampling distribution of mean. We plot the values of 100 items to see the 'spread' of the distribution and also compute the mean of that values (here, it is approaching poulation mean with the 'proper' choice of k).\n",
        "\n"
      ],
      "metadata": {
        "id": "GhyhVx0K1ZC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "I8QVhEmq06GF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#INPUTS\n",
        "n=100 #sample size\n",
        "k=50 #Repetition"
      ],
      "metadata": {
        "id": "LIv0n-y82M8D"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg(a) :\n",
        "    return(np.mean(np.random.rand(a)))\n",
        "\n",
        "data=np.full(k,n)\n",
        "new_list = list(map(avg,data))"
      ],
      "metadata": {
        "id": "N-P0oH-B0-TB"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd=pd.DataFrame(new_list)\n",
        "dd.columns=[\"Avg\"]\n",
        "np.mean(dd['Avg'])"
      ],
      "metadata": {
        "id": "HU1fv5rC1CLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(dd)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "4uvd68sL1GrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## <font color=darkgreen>Some Useful Statistic - Function of random sample that has no parameter\n",
        "\n",
        "Let $X_1,......X_n$ be a random sample from a density $f(X|\\theta$), then some statistics are\n",
        "\n",
        "**1. Sample Mean**\n",
        "\n",
        "  $\\bar{X_n} = \\frac{1}{n}\\sum X_i$\n",
        "  \n",
        "**2. Sample moments about Zero**\n",
        "\n",
        "  $M^{'}_r = \\frac{1}{n}\\sum X^r_i$  \n",
        "\n",
        "**3. Sample moments about $\\bar{X_n}$**\n",
        "    \n",
        "  ${M_r}  = \\frac{1}{n}\\sum(X_i-\\bar{X})^r$\n",
        "  \n",
        "**4. Sample Variance**\n",
        "  \n",
        "  ${S^2}  = \\frac{1}{(n-1)}\\sum(X_i-\\bar{X})^2$\n",
        "                                            \n",
        "For a random variable X, consider population $r^{th}$ moments \n",
        "\n",
        "1. Non central moments: $\\mu^{'}_r = E[X^r]$\n",
        "\n",
        "2. Central moments:$\\mu_r = E[(X-\\mu)^r]$\n",
        "\n",
        "In particular, the Mean of X is $\\mu = \\mu_1^{'} = E(X)$ \n",
        "  \n",
        "Now, Consider $M^{'}_r$\n",
        "  \n",
        "  $E[M^{'}_r] = E\\Big[\\frac{1}{n}\\sum_{i=1}^n {X_i}^r\\Big]$\n",
        "  \n",
        "  $=\\frac{1}{n}\\sum E({X_i}^r)$\n",
        "  \n",
        "  $=\\frac{1}{n}\\sum {\\mu'_r}$\n",
        "  \n",
        "  $\\Rightarrow E[M'_r] = {\\mu'_r}$\n",
        "   \n",
        "Also $V[M^{'}_r] = V \\Big[\\frac{1}{n}\\sum {X_i}^r\\Big]$ where V denotes the variance\n",
        "   \n",
        "   $= \\frac{1}{n^2}\\sum V({X_i}^r)$\n",
        "   \n",
        "   $= \\frac{1}{n}\\Big[E({X_i}^{2r}) - E({X_i^r})^2\\Big]$\n",
        "   \n",
        "   $V\\Big[{M'_r}\\Big] = \\frac{1}{n}\\Big[{\\mu'_{2r}}-{\\mu'_r}^2\\Big]$\n",
        "  \n",
        "  In Particular if r = 1,\n",
        "  \n",
        "1. $E[M^{'}_1] = E[\\bar{X_n}] = \\mu^{'}_1 = \\mu$\n",
        "\n",
        "2. $V[M^{'}_1] = V[\\bar{X}_n]$\n",
        "\n",
        "   $= \\frac{1}{n}[\\mu^{'}_2 - ({\\mu^{'}_1})^2]$\n",
        "   \n",
        "  $= \\frac{1}{n}{\\sigma}^2$\n",
        "  \n",
        "This holds for any $f(X~|~\\theta)$ with $\\mu = E(X)$ and $\\sigma^2 = V(X)$\n",
        "\n",
        "**Regarding Sample Variance:**\n",
        "\n",
        "${S^2}  = \\frac{1}{n-1}\\sum(X_i-\\bar{X})^2$\n",
        "  \n",
        "$E[S^2] = \\frac{1}{n}\\sum_{i=1}^n E{({X_i}-\\bar X)}^2$\n",
        " \n",
        "\n",
        "Now, $\\sum{({X_i}-\\mu)}^2 = \\sum{({X_i}-\\bar{X}+\\bar{X}-\\mu)}^2$\n",
        " \n",
        " $= \\sum[{({X_i}-\\bar{X})}^2 + {(\\bar{X}-\\mu)}^2 + 2({X_i}-\\bar{X})(\\bar{X}-\\mu)]$\n",
        " \n",
        " $= \\sum{({X_i}-\\bar{X})}^2 + n{(\\bar{X}-\\mu)}^2 + 2(\\bar{X}-\\mu)\\sum({X_i} -\\bar{X})$\n",
        " \n",
        "Since,$2(\\bar{X}-\\mu)\\sum({X_i}-\\bar{X}) = 0$\n",
        "  \n",
        "$\\sum {({X_i}-\\mu)}^2$\n",
        "\n",
        "$= \\sum{({X_i}-\\bar{X})}^2 + n{(\\bar{X}-\\mu)}^2$\n",
        "  \n",
        "So\n",
        "\n",
        "$E[S^2] = \\frac{1}{n-1} E\\Big[\\sum {({X_i}-\\mu)}^2  - n{(\\bar{X}-\\mu)}^2\\Big]$\n",
        "\n",
        "$= \\frac{1}{n-1} [\\sum E{({X_i}-\\mu)}^2  - nE{(\\bar{X}-\\mu)}^2 ]$\n",
        "\n",
        "$= \\frac{1}{n-1} \\Big[\\sum {\\sigma}^2  - nV(\\bar{X})\\Big]$\n",
        "\n",
        "$= \\frac{1}{n-1} [n{\\sigma}^2  - n \\frac{{\\sigma}^2}{n}]$\n",
        "\n",
        "$= {\\sigma}^2$\n",
        "  \n",
        "\n",
        "Hence for $X_1, X_2, .....X_n \\sim f(X~|~\\theta)$  then \n",
        "  \n",
        "  $E[S^2] = {\\sigma}^2$\n",
        "  \n",
        "Also, $V[S^2] =  \\frac{1}{n}\\Big[\\mu_4 - \\frac{n-3}{n-1}\\mu_2^2\\Big]$\n",
        "  \n",
        "###<font color=darkblue> Example 1.  \n",
        "\n",
        "Let $X_1, X_2, .....X_n \\sim Bern~(\\theta)$\n",
        "  \n",
        "  Using the properties of sample mean, \n",
        "   \n",
        "  $E[\\bar{X}]=\\mu = \\theta$ \n",
        "  \n",
        "  $V[\\bar{X}]=\\frac{\\sigma^2}{n} = \\frac{\\theta(1-\\theta)}{n}$ \n",
        "  \n",
        "\n",
        "###<font color=darkblue> Example 2.  \n",
        "\n",
        "Let $X_1, X_2, .....X_n \\sim Poisson~(\\theta)$\n",
        " \n",
        "  Using the properties of sample mean \n",
        "  \n",
        "  $E[\\bar{X}]=\\mu = \\theta$ \n",
        "  \n",
        "  $V[\\bar{X}]=\\frac{\\sigma^2}{n} = \\frac{\\theta}{n}$ \n",
        "  \n",
        "###<font color=darkblue> Example 3.  \n",
        "\n",
        "Let $X_1, X_2, .....X_n \\sim Expo (\\theta)$\n",
        "\n",
        "Here, $\\theta$ is the rate parameter(=$\\frac{1}{scale}$)\n",
        "\n",
        "This example illustrates the distribution of sample mean. \n",
        "  \n",
        "  $\\sum X_i \\sim Gamma~(n,\\theta)$\n",
        "  \n",
        "PDF is $\\frac{{\\theta}^n}{\\sqrt{n}}z^{n-1} e^{-\\theta z}$ \n",
        "\n",
        "where  $Z = \\sum {X_i}>0$\n",
        "  \n",
        "$\\Rightarrow p\\Big[\\sum X_i\\leq y\\Big]=\\int_0^y ~\\frac{\\theta^n}{\\sqrt{n}} z^{n-1} e^{-\\theta z}~dz$\n",
        "  \n",
        "$p[\\bar{X} \\leq \\frac{y}{n}] = \\int_0^y\\frac{{\\theta}^n}{\\sqrt{n}}z^{n-1} e^{-\\theta z} ~dz$\n",
        "  \n",
        "Now, $x =\\frac{y}{n} \\Rightarrow  y = nx$\n",
        "  \n",
        "$p[\\bar{X_n} \\leq {x}] = \\int_0^{nx}\\frac{{\\theta}^n}{\\sqrt{n}}z^{n-1} e^{-\\theta z}~dz$\n",
        "  \n",
        "Let $u =\\frac{\\sum{x_i}}{n}=\\frac{z}{n}$\n",
        "  \n",
        "When z = 0, then u = 0; when z = nx then u = x.  Also z = un implies dz = ndu\n",
        "\n",
        "$p[\\bar{X_n} \\leq {x}] = \\int_0^{x}\\frac{{\\theta}^n}{\\sqrt{n}} {(un)}^{n-1}e^{-n~\\theta~u}~n~du$\n",
        "\n",
        "$= \\int_0^{x}\\frac{{(n\\theta)}^n}{\\sqrt{n}} {u}^{n-1}e^{-n\\theta u}~du$\n",
        "  \n",
        "Therefore $\\bar{X}$, sample mean follows Gamma(n,n$\\theta$). Hence,we have the following results from the summaries of a Gamma distribution with rate parameter $\\theta$\n",
        "  \n",
        "1. Mean of $\\bar{X}$ is $E\\Big[\\bar{X}\\Big]=\\frac{n}{n\\theta}=\\frac{1}{\\theta}$\n",
        "\n",
        "2. Variance of $\\bar{X}$ is $V\\Big[\\bar{X}\\Big]=\\frac{n}{n^2\\theta^2}=\\frac{1}{n\\theta^2}$ \n",
        "\n",
        "Further one can easily understand that these results are the same when it is obtained from the properties of sample mean, when $X_1, X_2, .....X_n \\sim Expo (\\theta)$.\n",
        "                  \n",
        "\n",
        "###<font color=darkblue> Results regarding Normal distribution/Random sample from Normal population\n",
        "\n",
        "Let $X_1, X_2, .....X_n \\sim N({\\mu},~{\\sigma}^2)$ then\n",
        "\n",
        "\n",
        "1. $\\frac{\\bar X-\\mu}{\\sigma} \\sim N(0,\\frac{1}{n})$\n",
        "       \n",
        "2. $\\bar X$ and $\\sum(X_i-\\bar X)^2$ are mutually independent\n",
        "       \n",
        "3. $\\frac{(n-1)s^2}{\\sigma^2} \\sim {\\chi^2_{(n-1)}}$\n",
        "  \n",
        "  \n",
        "## <font color=darkgreen> These results exemplify the way sampling distributions are defined for a statistic"
      ],
      "metadata": {
        "id": "5kRqx36v03QE"
      }
    }
  ]
}